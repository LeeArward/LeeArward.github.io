<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>post</title>
    <link href="/2020/06/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95/"/>
    <url>/2020/06/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="大数据面试"><a href="#大数据面试" class="headerlink" title="大数据面试"></a>大数据面试</h1><pre><code class="hljs html">1、简述对大数据组件的理解？Yarn：大数据组件运行的job的管理器Spark：分布式的利用内存进行分布式运算的大数据组件Hbase：基于Hadoop的大数据常用数据库Hive：基于Hadoop的大数据数据仓库，操作和关系型数据库（MySQL）类似2、hdfs文件系统中NameNode和DataNode的区别和联系？NameNode存储了元数据，并且调度，协调整个集群DataNode主要用来存储数据3、讲述一下HDFS上传文件的流程① 由客户端 向 NameNode节点节点 发出请求;②NameNode 向Client返回可以可以存数据的 DataNode 这里遵循机架感应原则;③客户端 首先 根据返回的信息 先将 文件分块(Hadoop2.X版本 每一个block为 128M 而之前的版本为 64M;④然后通过NameNode返回的DataNode信息 直接发送给DataNode 并且是 流式写入同时会复制到其他两台机器;⑤dataNode 向 Client通信 表示已经传完 数据块 同时向NameNode报告 ⑥依照上面(④到⑤)的原理将 所有的数据块都上传结束   向 NameNode 报告 表明 已经传完所有的数据块 。4、了解zookeeper吗?介绍一下它，它的选举机制和集群的搭建。ZooKeeper 是一个开源的分布式协调服务，是 Google Chubby 的开源实现。分布式应用程序可以基于 ZooKeeper   实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。公司使用的flume集群，Kafka集群等等，都离不开ZooKeeper。每个节点上都要搭建ZooKeeper服务。首先我们要在每台pc上配置zookeeper环境变量，在cd到zookeeper下的conf文件夹下在zoo_simjle.cfg文件中添加datadir路径，再到zookeeper下新建data文件夹，创建myid，在文件里添加上server的ip地址。在启动zkserver.sh   start。5、分布式引发的问题死锁：至少有一个线程占用了资源，但是不占用CPU活锁：所有线程都没有把持资源，但是线程却是在不断地调度占用CPU需要引入一个管理节点为了防止入口的单点问题，需要引入管理节点的集群需要在管理阶段中选举出一个主节点需要确定一套选举算法主节点和从节点之间要保证数据的一致6、Avro的介绍？是序列化和RPC的框架。Avro一开始是Apache Hadoop的子件之一，但是后来发现Avro不只可以用于Hadoop而是可以用于多个场景下的序列化，所以单立出来形成一个新的组件。7、flume的介绍？Flume最早是Cloudera提供的日志收集系统，后贡献给Apache。所以目前是Apache下的项目，Flume支持在日志系统中定制各类数据发送方，用于收集数据。Flume是一个高可用的，高可靠的 鲁棒性（robust 健壮性），分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据(source);同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力(sink)。8、Hbase的表的设计原则？1、列族的数量及列族的势建议将HBase列族的数量设置的越少越好。当强，对于两个或两个以上的列族HBase并不能处理的很好。这是由于HBase的Flushing和压缩是基于Region的。当一个列族所存储的数据达到Flushing的阈值时，该表中所有列族将同时进行Flushing操作。这将带来不必要的I/O开销，列族越多，该特性带来的影响越大。此外，还要考虑到同一个表中不同列族所存储的记录数量的差别，即列族的势(Cardinality)。当两个列族数量差别过大时会使包含记录数量较少列族的数据分散在多个Region上，而Region有可能存储在不同的RegionServer上。这样，当进行查询或scan操作的时候，系统效率将会受到影响。2、行键(RowKey)的设计首先应该避免使用时序或单调(递减/递增)行键。因为当数据到来的时候，HBase首先需要根据记录的行键来确定存储的位置，即Region的位置，如果使用时序或单调行键，那么连续到来的数据将被分配到同一个Region中，而此时系统的其他Region/RegionServer处于空闲状态，这是分布式最不希望看到的状态。3、尽量最小化行键和列族的大小在HBase中，一个具体的值由存储该值的行键、对应的列(列族：列)以及该值的时间戳决定。HBase中索引是为了加速随即访问的速度，索引的创建是基于“行键+列族：列+时间戳+值”的，如果行键和列族的大小过大，甚至超过值本身的大小，纳闷将会增加索引的大小。并且在HBase中数据记录往往非常之多，重复的行键、列将不但使索引的大小过大，也将加重系统的负担4、版本的数量默认情况下为3个，可以通过HColumnDescriptor进行设置，建议不要设置的过大9、Hadoop的文件读流程和写流程？1、读流程：客户端发起RPC请求访问NameNodeNameNode查询元数据，找到这个文件的存储位置对应数据块的信息NameNode将文件对应的数据块的节点地址的全部或者部分放入一个队列中然后返回client收到这个数据块对应的节点地址client会从队列中取出第一个数据块对应的节点地址，会从这些节点地址中选取一个最近的节点进行读取将Block读取之后，对Block进行shecksum的验证，如果验证失败，说明数据块产生损坏，那么client会向NameNode发送信息说明该节点上的数据块损坏，然后从其他节点中再次读取这个数据块验证成功，则从队列中取出下一个Block的地址，然后继续读取当把这一次的文件快全部读取完成之后，client会向NameNode要下一批Block的地址当把文件全部读取完成之后，从client会向NameNode发送一个读取完毕的信号，，NameNode就会关闭对应的文件2、写流程：client发送RPC请求给NameNodeNameNode接收到请求之后，对请求进行验证，例如这个请求中的文件是否存在，再例如权限验证如果验证通过，NameNode确定文件的大小以及分块的数量，确定对应的节点（会去找磁盘空间相对空闲的节点来使用），将节点地址放入队列中返回客户端收到地址以后，从队列中依次取出节点地址，然后数据块依次放入对应的节点地址上客户端在写完之后就会向NameNode发送写完数据的信号，NameNode会给客户端一个关闭文件的信号DataNode之间将会通过管道进行自动备份，保证复本数量10、hive与mysql（传统数据库）的区别？查询语言不同：hive是hql语言，mysql是sql语言数据存储位置不同：hive是把数据存储在hdfs上，mysql数据是存储在自己的系统中数据格式：hive数据格式用户可以自定义，mysql有自己的系统定义格式数据更新：hive不支持数据更新，只可以读，不可以写，而sql支持数据更新索引：hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢的原因，而mysql有索引；延迟性：hive延迟性高，原因就是上边一点所说的，而mysql延迟性低；数据规模：hive存储的数据量超级大，而mysql只是存储一些少量的业务数据；底层执行原理：hive底层是用的mapreduce，而mysql是excutor执行器；————————————————版权声明：本文为CSDN博主「大致若愚」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/m0_38010471/java/article/details/85700200</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Flink数据源接入数据</title>
    <link href="/2020/06/25/Flink%E6%95%B0%E6%8D%AE%E6%BA%90%E6%8E%A5%E5%85%A5%E6%95%B0%E6%8D%AE/"/>
    <url>/2020/06/25/Flink%E6%95%B0%E6%8D%AE%E6%BA%90%E6%8E%A5%E5%85%A5%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="Flink数据源接入数据"><a href="#Flink数据源接入数据" class="headerlink" title="Flink数据源接入数据"></a>Flink数据源接入数据</h1><pre><code class="hljs pgsql">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();// <span class="hljs-keyword">read</span> <span class="hljs-type">text</span> file <span class="hljs-keyword">from</span> <span class="hljs-keyword">local</span> files <span class="hljs-keyword">system</span>DataSet&lt;String&gt; localLines = env.readTextFile("file:///path/to/my/textfile");// <span class="hljs-keyword">read</span> <span class="hljs-type">text</span> file <span class="hljs-keyword">from</span> an HDFS running at nnHost:nnPortDataSet&lt;String&gt; hdfsLines = env.readTextFile("hdfs://nnHost:nnPort/path/to/my/textfile");// <span class="hljs-keyword">read</span> a CSV file <span class="hljs-keyword">with</span> three fieldsDataSet&lt;Tuple3&lt;<span class="hljs-type">Integer</span>, String, <span class="hljs-type">Double</span>&gt;&gt; csvInput = env.readCsvFile("hdfs:///the/CSV/file")                       .<span class="hljs-keyword">types</span>(<span class="hljs-type">Integer</span>.<span class="hljs-keyword">class</span>, String.<span class="hljs-keyword">class</span>, <span class="hljs-type">Double</span>.<span class="hljs-keyword">class</span>);// <span class="hljs-keyword">read</span> a CSV file <span class="hljs-keyword">with</span> five fields, taking <span class="hljs-keyword">only</span> two <span class="hljs-keyword">of</span> themDataSet&lt;Tuple2&lt;String, <span class="hljs-type">Double</span>&gt;&gt; csvInput = env.readCsvFile("hdfs:///the/CSV/file")                               .includeFields("10010")  // take the first <span class="hljs-keyword">and</span> the fourth field                       .<span class="hljs-keyword">types</span>(String.<span class="hljs-keyword">class</span>, <span class="hljs-type">Double</span>.<span class="hljs-keyword">class</span>);// <span class="hljs-keyword">read</span> a CSV file <span class="hljs-keyword">with</span> three fields <span class="hljs-keyword">into</span> a POJO (Person.<span class="hljs-keyword">class</span>) <span class="hljs-keyword">with</span> corresponding fieldsDataSet&lt;Person&gt;&gt; csvInput = env.readCsvFile("hdfs:///the/CSV/file")                         .pojoType(Person.<span class="hljs-keyword">class</span>, "name", "age", "zipcode");// <span class="hljs-keyword">read</span> a file <span class="hljs-keyword">from</span> the specified <span class="hljs-type">path</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">type</span> SequenceFileInputFormatDataSet&lt;Tuple2&lt;IntWritable, <span class="hljs-type">Text</span>&gt;&gt; tuples = env.createInput(HadoopInputs.readSequenceFile(IntWritable.<span class="hljs-keyword">class</span>, <span class="hljs-type">Text</span>.<span class="hljs-keyword">class</span>, "hdfs://nnHost:nnPort/path/to/file"));// creates a <span class="hljs-keyword">set</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">some</span> given elementsDataSet&lt;String&gt; <span class="hljs-keyword">value</span> = env.fromElements("Foo", "bar", "foobar", "fubar");// generate a number <span class="hljs-keyword">sequence</span>DataSet&lt;Long&gt; numbers = env.generateSequence(<span class="hljs-number">1</span>, <span class="hljs-number">10000000</span>);// <span class="hljs-keyword">Read</span> data <span class="hljs-keyword">from</span> a relational <span class="hljs-keyword">database</span> <span class="hljs-keyword">using</span> the JDBC <span class="hljs-keyword">input</span> <span class="hljs-keyword">format</span>DataSet&lt;Tuple2&lt;String, <span class="hljs-type">Integer</span>&gt; dbData =    env.createInput(      JDBCInputFormat.buildJDBCInputFormat()                     .setDrivername("org.apache.derby.jdbc.EmbeddedDriver")                     .setDBUrl("jdbc:derby:memory:persons")                     .setQuery("select name, age from persons")                     .setRowTypeInfo(<span class="hljs-built_in">new</span> RowTypeInfo(BasicTypeInfo.STRING_TYPE_INFO, BasicTypeInfo.INT_TYPE_INFO))                     .finish()    );</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Eclipse快捷键大全</title>
    <link href="/2020/06/25/Eclipse%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8/"/>
    <url>/2020/06/25/Eclipse%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Eclipse快捷键大全"><a href="#Eclipse快捷键大全" class="headerlink" title="Eclipse快捷键大全"></a>Eclipse快捷键大全</h1><pre><code class="hljs html">快捷方式<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>0. Ctrl + 1 （快速修复）<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>1. Ctrl + D （删除当前行)<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>2. Ctrl + Alt + ↓（复制当前行到下一行）<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>3. Alt + / 或者说是 Ctrl + 空格（由于后者与输入法的快捷键冲突，所以，我一般都用前者） 作用：快速插入。<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>4. Alt+Shift+R 重命名非常好用。<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>5. Ctrl + Q 定位到最后编辑的地方。<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>6. Ctrl + Shift + O 自动导入包。<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>7. Ctrl+/ 注释当前行,再按则取消注释。 [7] <span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>8. Ctrl+K快速查找。<span class="hljs-comment">&lt;!--[if !supportLists]--&gt;</span>9. Ctrl + Shift + F 自动缩进。常用快捷键Eclipse最全快捷键，熟悉快捷键可以帮助开发事半功倍，节省更多的时间来用于做有意义的事情。Ctrl +1 快速修复(最经典的快捷键,就不用多说了)Ctrl+D: 删除当前行Ctrl+Alt+↓ 复制当前行到下一行(复制增加)Ctrl+Alt+↑ 复制当前行到上一行(复制增加)Alt+↓ 当前行和下面一行交互位置(特别实用,可以省去先剪切,再粘贴了)Alt+↑ 当前行和上面一行交互位置(同上)Alt+← 前一个编辑的页面Alt+→ 下一个编辑的页面(当然是针对上面那条来说了)Alt+Enter 显示当前选择资源(工程,or 文件 or文件)的属性Alt+/ 补全当前所输入代码Shift+Enter 在当前行的下一行插入空行(这时鼠标可以在当前行的任一位置,不一定是最后)Shift+Ctrl+Enter 在当前行插入空行(原理同上条)Ctrl+Q 定位到最后编辑的地方Ctrl+L 定位在某行 (对于程序超过100的人就有福音了)Ctrl+M 最大化当前的Edit或View (再按则反之)Ctrl+/ 注释当前行,再按则取消注释Ctrl+O 快速显示 OutLineCtrl+T 快速显示当前类的继承结构Ctrl+W 关闭当前EditerCtrl+K 参照选中的Word快速定位到下一个Ctrl+E 快速显示当前Editer的下拉列表(如果当前页面没有显示的用黑体表示)Ctrl+/(小键盘) 折叠当前类中的所有代码Ctrl+×(小键盘) 展开当前类中的所有代码Ctrl+Space 代码助手完成一些代码的插入(但一般和输入法有冲突,可以修改输入法的热键,也可以暂用Alt+/来代替)Ctrl+Shift+E 显示管理当前打开的所有的View的管理器(可以选择关闭,激活等操作)Ctrl+J 正向增量查找(按下Ctrl+J后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在stutes line中显示没有找到了,查一个单词时,特别实用,这个功能Idea两年前就有了)Ctrl+Shift+J 反向增量查找(和上条相同,只不过是从后往前查)Ctrl+Shift+F4 关闭所有打开的EditerCtrl+Shift+X 把当前选中的文本全部变为大写Ctrl+Shift+Y 把当前选中的文本全部变为小写Ctrl+Shift+F 格式化当前代码Ctrl+Shift+P 定位到对于的匹配符(譬如&#123;&#125;) (从前面定位后面时,光标要在匹配符里面,后面到前面,则反之)下面的快捷键是重构里面常用的,本人就自己喜欢且常用的整理一下(注:一般重构的快捷键都是Alt+Shift开头的了)Alt+Shift+R 重命名 (是我自己最爱用的一个了,尤其是变量和类的Rename,比手工方法能节省很多劳动力)Alt+Shift+M 抽取方法 (这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用)Alt+Shift+C 修改函数结构(比较实用,有N个函数调用了这个方法,修改一次搞定)Alt+Shift+L 抽取本地变量( 可以直接把一些魔法数字和字符串抽取成一个变量,尤其是多处调用的时候)Alt+Shift+F 把Class中的local变量变为field变量 (比较实用的功能)Alt+Shift+I 合并变量(可能这样说有点不妥Inline)Alt+Shift+V 移动函数和变量(不怎么常用)Alt+Shift+Z 重构的后悔药(Undo)</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pom.xml文件配置</title>
    <link href="/2020/06/25/pom-xml%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE/"/>
    <url>/2020/06/25/pom-xml%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><blockquote><p>此处记录Intellij IDEA编辑器下的 <code>pom.xml</code> 文件的正确配置格式。</p></blockquote><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">project</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">"http://maven.apache.org/POM/4.0.0"</span></span><span class="hljs-tag">         <span class="hljs-attr">xmlns:xsi</span>=<span class="hljs-string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><span class="hljs-tag">         <span class="hljs-attr">xsi:schemaLocation</span>=<span class="hljs-string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">modelVersion</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">modelVersion</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>cn.tedu<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-1910<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0-SNAPSHOT<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.10.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-streaming-java_2.11<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.10.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-clients_2.11<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.10.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">project</span>&gt;</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>pom</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FirstPost</title>
    <link href="/2020/06/21/FirstPost/"/>
    <url>/2020/06/21/FirstPost/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这是我的第一篇文章。</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>正文在此。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/06/21/hello-world/"/>
    <url>/2020/06/21/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
